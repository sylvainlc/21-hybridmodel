@book{sarkka2013bayesian,
author = {S\"arkk\"a, S.},
title = {Bayesian Filtering and Smoothing},
year = {2013},
publisher = {Cambridge University Press},
address = {New York, NY, USA}
} 

@book{douc2014nonlinear,
title={Nonlinear time series: Theory, methods and applications with R examples},
author={Douc, Randal and Moulines, Eric and Stoffer, David},
year={2014},
publisher={CRC press}
}

@book{zucchini2017hidden,
title={Hidden Markov models for time series: an introduction using R},
author={Zucchini, Walter and MacDonald, Iain L and Langrock, Roland},
year={2017},
publisher={CRC press}
}

@ARTICLE{RePEc:inm:oropre:v:9:y:1961:i:5:p:673-685,
title = {The Fundamental Theorem of Exponential Smoothing},
author = {Brown, Robert G. and Meyer, Richard F.},
year = {1961},
journal = {Operations Research},
volume = {9},
number = {5},
pages = {673-685}
}

@book{box2015time,
title={Time series analysis: forecasting and control},
author={Box, George EP and Jenkins, Gwilym M and Reinsel, Gregory C and Ljung, Greta M},
year={2015},
publisher={John Wiley \& Sons}
}

@article{touron2019consistency,
title={Consistency of the maximum likelihood estimator in seasonal hidden Markov models},
author={Touron, Augustin},
journal={Statistics and Computing},
volume={29},
number={5},
pages={1055--1075},
year={2019},
publisher={Springer}
}

@misc{touron2017modeling,
title={Modeling rainfalls using a seasonal hidden markov model}, 
author={Augustin Touron},
year={2017},
eprint={1710.08112},
archivePrefix={arXiv},
primaryClass={stat.AP}
}

@article{hochreiter1997long,
title={Long short-term memory},
author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
journal={Neural computation},
volume={9},
number={8},
pages={1735--1780},
year={1997},
publisher={MIT Press}
}

@article{vaswani2017attention,
title={Attention Is All You Need},
author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
year={2017},
journal={31st Conference on Neural Information Processing Systems (NeurIPS 2017)}
}

@article{makridakis2018m4,
title={The {M}4 Competition: Results, findings, conclusion and way forward},
author={Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
journal={International Journal of Forecasting},
volume={34},
number={4},
pages={802--808},
year={2018},
publisher={Elsevier}
}

@article{makridakis2020m4,
title={The {M}4 Competition: 100,000 time series and 61 forecasting methods},
author={Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
journal={International Journal of Forecasting},
volume={36},
number={1},
pages={54--74},
year={2020},
publisher={Elsevier}
}

@article{smyl2020hybrid,
title={A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting},
author={Smyl, Slawek},
journal={International Journal of Forecasting},
volume={36},
number={1},
pages={75--85},
year={2020},
publisher={Elsevier}
}

@article{li2014armax,
title={An ARMAX model for forecasting the power output of a grid connected photovoltaic system},
author={Li, Yanting and Su, Yan and Shu, Lianjie},
journal={Renewable Energy},
volume={66},
pages={78--89},
year={2014},
publisher={Elsevier}
}

@inproceedings{laptev2017time,
title={Time-series extreme event forecasting with neural networks at uber},
author={Laptev, Nikolay and Yosinski, Jason and Li, Li Erran and Smyl, Slawek},
booktitle={International conference on machine learning},
volume={34},
pages={1--5},
year={2017}
}

@article{salinas2020deepar,
title={DeepAR: Probabilistic forecasting with autoregressive recurrent networks},
author={Salinas, David and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim},
journal={International Journal of Forecasting},
volume={36},
number={3},
pages={1181--1191},
year={2020},
publisher={Elsevier}
}

@article{li2019enhancing,
title={Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting},
author={Li, Shiyang and Jin, Xiaoyong and Xuan, Yao and Zhou, Xiyou and Chen, Wenhu and Wang, Yu-Xiang and Yan, Xifeng},
journal={arXiv preprint arXiv:1907.00235},
year={2019}
}

@INPROCEEDINGS{8614252,
author={Siami-Namini, Sima and Tavakoli, Neda and Siami Namin, Akbar},
booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
title={A Comparison of {ARIMA} and {LSTM} in Forecasting Time Series}, 
year={2018},
volume={},
number={},
pages={1394-1401},
doi={10.1109/ICMLA.2018.00227}
}
 
@article{zhang2003time,
title={Time series forecasting using a hybrid {ARIMA} and neural network model},
author={Zhang, G Peter},
journal={Neurocomputing},
volume={50},
pages={159--175},
year={2003},
publisher={Elsevier}
}

@book{rogersdiffusion,
title={Diffusion of innovations},
author={Rogers, Everett M},
year={1962},
publisher={Simon and Schuster}
}

@article{jianwei2019novel,
title={A novel hybrid model on the prediction of time series and its application for the gold price analysis and forecasting},
author={Jianwei, E and Ye, Jimin and Jin, Haihong},
journal={Physica A: Statistical Mechanics and its Applications},
volume={527},
pages={121454},
year={2019},
publisher={Elsevier}
}
@article{bandara2020lstm,
title={{LSTM-MSNet}: Leveraging forecasts on sets of related time series with multiple seasonal patterns},
author={Bandara, Kasun and Bergmeir, Christoph and Hewamalage, Hansika},
journal={IEEE transactions on neural networks and learning systems},
year={2020},
publisher={IEEE}
}

@article{lim2019temporal,
title={Temporal fusion transformers for interpretable multi-horizon time series forecasting},
author={Lim, Bryan and Arik, Sercan O and Loeff, Nicolas and Pfister, Tomas},
journal={arXiv preprint arXiv:1912.09363},
year={2019}
}

@article{martin2020monte,
title={The {M}onte {C}arlo {T}ransformer: a stochastic self-attention model for sequence prediction},
author={Martin, Alice and Ollion, Charles and Strub, Florian and Le Corff, Sylvain and Pietquin, Olivier},
journal={arXiv preprint arXiv:2007.08620},
year={2020}
}

@article{hyndman2020package,
title={Package ‘forecast’},
author={Hyndman, Rob J and Athanasopoulos, George and Bergmeir, Christoph and Caceres, Gabriel and Chhay, Leanne and O'Hara-Wild, Mitchell and Petropoulos, Fotios and Razbash, Slava and Wang, Earo},
journal={Online] https://cran. r-project. org/web/packages/forecast/forecast. pdf},
year={2020}
}
@article{doi:10.1198/jasa.2011.tm09771,
author = {Alysha M. De Livera and Rob J. Hyndman and Ralph D. Snyder},
title = {Forecasting Time Series With Complex Seasonal Patterns Using Exponential Smoothing},
journal = {Journal of the American Statistical Association},
volume = {106},
number = {496},
pages = {1513-1527},
year  = {2011}
}

@article{MONTEROMANSO202086,
title = {FFORMA: Feature-based forecast model averaging},
journal = {International Journal of Forecasting},
volume = {36},
number = {1},
pages = {86-92},
year = {2020},
note = {M4 Competition},
issn = {0169-2070},
doi = {https://doi.org/10.1016/j.ijforecast.2019.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0169207019300895},
author = {Pablo Montero-Manso and George Athanasopoulos and Rob J. Hyndman and Thiyanga S. Talagala},
keywords = {Time series features, Forecast combination, XGBoost, M4 competition, Meta-learning},
abstract = {We propose an automated method for obtaining weighted forecast combinations using time series features. The proposed approach involves two phases. First, we use a collection of time series to train a meta-model for assigning weights to various possible forecasting methods with the goal of minimizing the average forecasting loss obtained from a weighted forecast combination. The inputs to the meta-model are features that are extracted from each series. Then, in the second phase, we forecast new series using a weighted forecast combination, where the weights are obtained from our previously trained meta-model. Our method outperforms a simple forecast combination, as well as all of the most popular individual methods in the time series forecasting literature. The approach achieved second position in the M4 competition.}
}
